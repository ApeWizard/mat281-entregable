{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJMGZL0drl4su4ef0RDcAo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ApeWizard/mat281-entregable/blob/main/docs/codes/homeworks/Tarea%201%20Aplica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problema 1:\n",
        "-Se importan librerias\n",
        "-Se usa try en caso de que hayan errores con el path que pone el usuario"
      ],
      "metadata": {
        "id": "2RTSeNU7RzsU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdp-ZTdGOzPn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "#Problema 1:\n",
        "try:\n",
        "    gatito = Image.open(\"images/gatito.png\")\n",
        "    gatito_np = np.array(gatito)\n",
        "\n",
        "    secret_list = []\n",
        "\n",
        "    for canal in range(gatito_np.shape[2]):\n",
        "        secret_aux = gatito_np[:, :, canal] % 2\n",
        "        secret_aux = secret_aux * 255\n",
        "        secret_aux = secret_aux.astype(np.uint8)\n",
        "        secret_list.append(secret_aux)\n",
        "\n",
        "    print(f\"la lista secreta tiene {len(secret_list)} elementos\")\n",
        "\n",
        "    secret_np = np.concatenate(secret_list, axis=1)\n",
        "    print(f\"shape de la imagen secreta: {secret_np.shape}\")\n",
        "\n",
        "    secret_img = Image.fromarray(secret_np, mode=\"L\")\n",
        "    secret_img.save(\"images/secret_revealed.png\")\n",
        "    print(\"Imagen secreta guardada\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Warning: No se encontro gatito.png: {e}\")\n",
        "\n",
        "# Problema 2:\n",
        "try:\n",
        "    my_img = Image.open(\"images/gatito.png\")\n",
        "\n",
        "    my_img_np = np.array(my_img.convert('L'))\n",
        "    print(f\"shape de imagen: {my_img_np.shape}\")\n",
        "\n",
        "    umbral = 20\n",
        "    my_img_np_aux = (my_img_np > umbral).astype(np.uint8)\n",
        "\n",
        "    my_img_split = np.array_split(my_img_np_aux, 3, axis=1)\n",
        "\n",
        "    cat = Image.open(\"images/gatito_original.png\")\n",
        "    cat_np = np.array(cat).copy()  #asegura escritura\n",
        "    print(f\"shape de imagen cargada: {cat_np.shape}\")\n",
        "\n",
        "\n",
        "    mask = cat_np % 2 == 1\n",
        "    cat_np[mask] -= 1\n",
        "\n",
        "    for channel in range(3):\n",
        "        cat_np[:, :, channel] += my_img_split[channel]\n",
        "\n",
        "    cat_secret_im = Image.fromarray(cat_np)\n",
        "    cat_secret_im.save(\"images/my_secret.png\")\n",
        "    print(\"Secreto guardado!\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Warning: No se pudo procesar la imagen para esconder: {e}\")\n",
        "\n",
        "def imagenception(filepath):\n",
        "    try:\n",
        "        img = Image.open(filepath)\n",
        "        img_np = np.array(img)\n",
        "        secret_list = []\n",
        "        for i in range(img_np.shape[2]):\n",
        "            secret_aux = (img_np[:, :, i] % 2) * 255\n",
        "            secret_list.append(secret_aux.astype(np.uint8))\n",
        "        secret_np = np.concatenate(secret_list, axis=1)\n",
        "        return Image.fromarray(secret_np, mode=\"L\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error con imagen: {e}\")\n",
        "        return None\n",
        "\n",
        "# Test\n",
        "try:\n",
        "    my_secret_img = imagenception(\"images/my_secret.png\")\n",
        "    if my_secret_img:\n",
        "        my_secret_img.save(\"images/decoded_secret.png\")\n",
        "        print(\"Decoding function tested successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not test decoding: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arriba esta el probema 1. Notar que los directorios varian segun computador y sistema operativo (Linux/Windows/Mac) entonces es necesario cambiar el path de las imagenes. Tanto donde se guardan como de donde se extraen. Esto aplica para los 3 problemas."
      ],
      "metadata": {
        "id": "eSU5hX3MRbZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problema 2: Si yo descargo los datos, se guardaran en un lugar especifico de mi escritorio, y no es apto para el usuario. Por esto, se asume que el usuario tiene los datos y debe usar su propio path para accederlos."
      ],
      "metadata": {
        "id": "5TV3gg40V8Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "    df_dict = {}\n",
        "    for year in [2015, 2016, 2017]:\n",
        "        try:\n",
        "            df = pd.read_csv(f\"data/world-happiness/{year}.csv\")\n",
        "            df_dict[year] = df.assign(Year=year)\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Warning: No existen datos para {year}\")\n",
        "\n",
        "    if not df_dict:\n",
        "        raise ValueError(\"No se encontraron los datos\")\n",
        "\n",
        "    intersection_columns = reduce(np.intersect1d,\n",
        "                                [df_i.columns.values for df_i in df_dict.values()]).tolist()\n",
        "    print(f\"Common columns: {intersection_columns}\")\n",
        "    #se usa reduce para conseguir las columnas columnas en caso de que difieran.\n",
        "\n",
        "\n",
        "    def clean_column_name(x):\n",
        "        x = x.lower().replace(' ', '_')\n",
        "        x = re.sub(r'\\([^)]*\\)', '', x)\n",
        "        x = x.strip('_')\n",
        "        return x\n",
        "    #Se limpian los nombres de columnas en caso de que no sean iguales.\n",
        "    happiness = (pd.concat(df_dict.values()).reset_index(drop=True)[intersection_columns].rename(columns=clean_column_name))\n",
        "\n",
        "    print(f\"dataframe shape: {happiness.shape}\")\n",
        "    print(f\"dataframe columns: {happiness.columns}\")\n",
        "    country_counts = happiness['country'].value_counts()\n",
        "    missing_all_years = country_counts[country_counts < 3]\n",
        "    print(f\"Countries missing measurements: {len(missing_all_years)}\")\n",
        "\n",
        "    bad_country_names_dict = {\n",
        "        \"Hong Kong S.A.R., China\": \"Hong Kong\",\n",
        "        \"Taiwan Province of China\": \"Taiwan\",\n",
        "        \"Somaliland region\": \"Somaliland Region\"\n",
        "    }\n",
        "    happiness = happiness.assign(\n",
        "        country=happiness['country'].replace(bad_country_names_dict)\n",
        "    )\n",
        "    #Aca se podria usar .map pero no se si es parte del curso\n",
        "\n",
        "    pivot_happiness = happiness.pivot(\n",
        "        index='year',\n",
        "        columns='country',\n",
        "        values='happiness_score'\n",
        "    ).fillna(\"\") #Se rellenan los valores NULL con \"\"\n",
        "\n",
        "    mean_happiness = happiness.groupby('country')['happiness_score'].mean().nlargest(3)\n",
        "    print(f\"Top 3 paises mas felices:\\n{mean_happiness}\")\n",
        "\n",
        "\n",
        "    factor_cols = [col for col in happiness.columns\n",
        "                   if col not in ['country', 'year', 'happiness_score', 'happiness_rank']\n",
        "                   and pd.api.types.is_numeric_dtype(happiness[col])]\n",
        "\n",
        "    if factor_cols:\n",
        "        hap_mean_factors = happiness.groupby('year')[factor_cols].mean()\n",
        "        print(f\"Factor con contribucion mas alta por a\\~no :\\n{hap_mean_factors.idxmax(axis=1)}\")\n",
        "    else:\n",
        "        print(\"No numeric factor columns found\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error procesando los datos {e}\")\n",
        "\n",
        "try:\n",
        "    suicide = pd.read_csv(\"data/suicide_rates.csv\")\n",
        "\n",
        "    suicides_agg = (\n",
        "        suicide.groupby(['country', 'year'])\n",
        "        .agg({\n",
        "            'population': 'sum',\n",
        "            'suicides_no': 'sum'\n",
        "        })\n",
        "        .reset_index()\n",
        "        .assign(\n",
        "            suicides_ratio_100k=lambda x: (x['suicides_no'] / x['population']) * 100000,\n",
        "            suicides_rank=lambda x: x.groupby('year')['suicides_ratio_100k']\n",
        "                                    .rank(method='dense', ascending=False)\n",
        "        )\n",
        "    )\n",
        "    #No se recomienda usar lambda porque es lento bases de datos muy grandes. Mas\n",
        "    #eficiente seria un metodo vectorizado con numpy o mejor aun numpy (especialmente ya que\n",
        "    #son numeros). Si se trata de valores string se suele hacer un \"embedding\".\n",
        "    if 'happiness' in locals():\n",
        "        hap_sui = happiness.merge(suicides_agg, on=['country', 'year'], how='inner')\n",
        "        #Merge puede duplicar valores si existen columnas iguales en los dataframes,\n",
        "        #Se suele borrar el que tiene prefijo \"_y\".\n",
        "        if 'happiness_rank' in hap_sui.columns and 'suicides_rank' in hap_sui.columns:\n",
        "            corr_ranks = hap_sui[['happiness_rank', 'suicides_rank']].corr().iloc[0, 1]\n",
        "            print(f\"Correlacion: {corr_ranks:.3f}\") #3 puntos decimales\n",
        "\n",
        "            # Correlacion por a\\~no:\n",
        "            corr_by_year = hap_sui.groupby('year').apply(\n",
        "                lambda x: x[['happiness_rank', 'suicides_rank']].corr().iloc[0, 1]\n",
        "            )\n",
        "            print(f\"Correlacion por a\\~no :\\n{corr_by_year}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Warning: suicide_rates.csv no se encontro\")\n",
        "except Exception as e:\n",
        "    print(f\"Error procesando: {e}\")"
      ],
      "metadata": {
        "id": "5_j82CS_SjF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problema 3:"
      ],
      "metadata": {
        "id": "nZgWzVYYVpUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "years = [2015, 2016, 2017, 2018, 2019, 2020]\n",
        "try:\n",
        "    import lxml\n",
        "    life_cost = (\n",
        "        pd.concat({\n",
        "            year: (\n",
        "                pd.read_html(f\"https://www.numbeo.com/cost-of-living/rankings.jsp?title={year}\")[1]\n",
        "                .rename(columns=lambda x: x.lower().replace(\" \", \"_\"))\n",
        "                .assign(rank=lambda x: x.index + 1)\n",
        "                .set_index(\"rank\")\n",
        "            ) for year in years\n",
        "        })\n",
        "        .rename_axis([\"year\", \"rank\"])\n",
        "        .reset_index()\n",
        "    )\n",
        "    print(f\"Datos cargados de shape {life_cost.shape}\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"lxml not installed - installing now...\")\n",
        "    import subprocess\n",
        "    subprocess.run(['pip', 'install', 'lxml', '-q'], capture_output=True)\n",
        "    print(\"Please restart the script after installation\")\n",
        "    life_cost = None\n",
        "    #Se instala lxml en caso de que el usuario no lo tenga\n",
        "except Exception as e:\n",
        "    print(f\"No se logro conseguir los datos en linea. Verificar que existe una conexion: {e}\")\n",
        "\n",
        "\n",
        "if life_cost is not None:\n",
        "    if 'cost_of_living_index' in life_cost.columns:\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        for i, year in enumerate(years):\n",
        "            year_data = life_cost[life_cost['year'] == year]['cost_of_living_index']\n",
        "            if not year_data.empty:\n",
        "                axes[i].hist(year_data, bins=20, edgecolor='black', alpha=0.7)\n",
        "                axes[i].set_title(f'Year {year}')\n",
        "                axes[i].set_xlabel('Cost of Living Index')\n",
        "                axes[i].set_ylabel('Frecuencia')\n",
        "                axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('cost_living_histograms.png')\n",
        "        plt.close()\n",
        "        print(\"Histogramas guardados!\")\n",
        "    else:\n",
        "        print(\"Warning: columna cost_of_living_index no encontrada\")\n",
        "\n",
        "\n",
        "    if 'restaurant_price_index' in life_cost.columns:\n",
        "        rol_seed = 202110551\n",
        "        np.random.seed(rol_seed)\n",
        "\n",
        "        unique_cities = life_cost['city'].unique()\n",
        "        n_cities = min(10, len(unique_cities))\n",
        "        my_cities = np.random.choice(unique_cities, size=n_cities, replace=False)\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        for city in my_cities:\n",
        "            city_data = life_cost[life_cost['city'] == city].sort_values('year')\n",
        "            if not city_data.empty:\n",
        "                plt.plot(city_data['year'], city_data['restaurant_price_index'],\n",
        "                        marker='o', label=city[:15])  #Truncar nombres largos\n",
        "\n",
        "        plt.xlabel('Year')\n",
        "        plt.ylabel('Restaurant Price Index')\n",
        "        plt.title('Evolucion del indice de Restaurante (10 Random Cities)')\n",
        "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('restaurant_index_evolution.png')\n",
        "        plt.close()\n",
        "        print(\"Imagen saved!\")\n",
        "    else:\n",
        "        print(\"Warning: restaurant_price_index column not found\")\n"
      ],
      "metadata": {
        "id": "jBzGLNxjWTZe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}